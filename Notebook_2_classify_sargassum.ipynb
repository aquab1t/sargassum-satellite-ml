{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2: Applying Models to Satellite Imagery\n",
    "\n",
    "This notebook demonstrates how to load pre-trained Sargassum detection models and apply them to Landsat-8 and Sentinel-2 scenes. It mirrors `2_classify.py` (TFLite) and `2_classify_ML.py` (XGBoost GPU).\n",
    "\n",
    "**Workflow:**\n",
    "1. Environment Setup\n",
    "2. Configuration — choose which models to run\n",
    "3. Define Core Processing Functions\n",
    "4. Load Models & Artefacts\n",
    "5. Classify Scenes (Landsat-8 + Sentinel-2)\n",
    "6. Visualize Fractional Cover Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup & Dependencies\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "**Key Library Versions:**\n",
    "- `numpy==1.26.4`\n",
    "- `scikit-learn==1.5.2`\n",
    "- `xgboost==2.1.4`\n",
    "- `tensorflow==2.17.0`\n",
    "- `rasterio==1.4.3`\n",
    "- `opencv-python==4.10.0.84`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Standard Library Imports ---\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import time\n",
    "import joblib\n",
    "import traceback\n",
    "\n",
    "# --- Third-party Library Imports ---\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import rasterio.windows\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "try:\n",
    "    from tqdm.notebook import tqdm\n",
    "except ImportError:\n",
    "    from tqdm import tqdm\n",
    "\n",
    "try:\n",
    "    import cv2\n",
    "    CV2_AVAILABLE = True\n",
    "except ImportError:\n",
    "    CV2_AVAILABLE = False\n",
    "    print('Warning: OpenCV not found. Multi-resolution resampling will be unavailable.')\n",
    "\n",
    "# --- TFLite (via TensorFlow) ---\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "TF_AVAILABLE = False\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    TF_AVAILABLE = True\n",
    "    print('TensorFlow loaded successfully.')\n",
    "except ImportError:\n",
    "    print('Warning: TensorFlow not found. TFLite models will be skipped.')\n",
    "\n",
    "# --- XGBoost ---\n",
    "XGB_AVAILABLE = False\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGB_AVAILABLE = True\n",
    "    print('XGBoost loaded successfully.')\n",
    "except ImportError:\n",
    "    print('Warning: XGBoost not found. XGBoost model will be skipped.')\n",
    "\n",
    "print('All libraries loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Specify which models to run. TFLite models require TensorFlow; XGBoost models require XGBoost.\n",
    "Edit `TFLITE_MODELS` and `XGBOOST_MODELS` to select which files to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Select models to run ---\n",
    "# TFLite options: 'mlp_classifier_int8.tflite', 'mlp_classifier_f16.tflite',\n",
    "#                 'cnn_classifier_int8.tflite', 'cnn_classifier_f16.tflite'\n",
    "TFLITE_MODELS = [\n",
    "    'mlp_classifier_int8.tflite',\n",
    "    'mlp_classifier_f16.tflite',\n",
    "    'cnn_classifier_int8.tflite',\n",
    "    'cnn_classifier_f16.tflite',\n",
    "]\n",
    "\n",
    "# XGBoost options: 'xgboost_gpu_classifier.joblib'\n",
    "XGBOOST_MODELS = [\n",
    "    'xgboost_gpu_classifier.joblib',\n",
    "]\n",
    "\n",
    "# --- Static paths (no need to change) ---\n",
    "MODEL_ROOT_DIR       = 'output/models_classification/'\n",
    "DATA_ROOT_DIR        = 'satellite_data/'\n",
    "OUTPUT_DIR           = 'output/fractional_cover_maps/'\n",
    "POSITIVE_CLASS_LABEL = 'sargassum'\n",
    "DISABLE_L8_HARMONIZATION = False\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print(f'TFLite models : {TFLITE_MODELS}')\n",
    "print(f'XGBoost models: {XGBOOST_MODELS}')\n",
    "print(f'Output dir    : {OUTPUT_DIR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Core Processing Functions\n",
    "\n",
    "All helper functions for loading artefacts, locating band files, and running windowed inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Sensor Configuration ──────────────────────────────────────────────────────\n",
    "TRAINING_BAND_ORDER = ['Blue', 'Green', 'Red', 'NIR', 'SWIR1']\n",
    "\n",
    "L8_TO_S2_HARMONIZATION_COEFFS = {\n",
    "    'Blue':  {'slope': 0.9778, 'intercept': 0.0048},\n",
    "    'Green': {'slope': 1.0379, 'intercept': -0.0009},\n",
    "    'Red':   {'slope': 1.0431, 'intercept': -0.0011},\n",
    "    'NIR':   {'slope': 0.9043, 'intercept': 0.0040},\n",
    "    'SWIR1': {'slope': 0.9872, 'intercept': -0.0001},\n",
    "}\n",
    "\n",
    "SENSOR_CONFIG = {\n",
    "    'Landsat-8': {\n",
    "        'name': 'Landsat-8',\n",
    "        'bands_needed': {'B2': 30, 'B3': 30, 'B4': 30, 'B5': 30, 'B6': 30},\n",
    "        'target_resolution': 30,\n",
    "        'band_map_to_train': {'B2': 'Blue', 'B3': 'Green', 'B4': 'Red', 'B5': 'NIR', 'B6': 'SWIR1'},\n",
    "        'scale': 0.0000275, 'offset': -0.2,\n",
    "        'file_patterns': {\n",
    "            'B2': ['*_B2.TIF'], 'B3': ['*_B3.TIF'], 'B4': ['*_B4.TIF'],\n",
    "            'B5': ['*_B5.TIF'], 'B6': ['*_B6.TIF'],\n",
    "        },\n",
    "        'harmonization_coeffs': L8_TO_S2_HARMONIZATION_COEFFS,\n",
    "    },\n",
    "    'Sentinel-2': {\n",
    "        'name': 'Sentinel-2',\n",
    "        'bands_needed': {'B02': 10, 'B03': 10, 'B04': 10, 'B08': 10, 'B8A': 20, 'B11': 20},\n",
    "        'target_resolution': 10,\n",
    "        'band_map_to_train': {\n",
    "            'B02': 'Blue', 'B03': 'Green', 'B04': 'Red',\n",
    "            'B08': 'NIR',  'B8A': 'NIR',  'B11': 'SWIR1',\n",
    "        },\n",
    "        'scale': 0.0001, 'offset': 0.0,\n",
    "        'file_patterns': {\n",
    "            'B02': ['**/R10m/*_B02_10m.jp2'], 'B03': ['**/R10m/*_B03_10m.jp2'],\n",
    "            'B04': ['**/R10m/*_B04_10m.jp2'], 'B08': ['**/R10m/*_B08_10m.jp2'],\n",
    "            'B8A': ['**/R20m/*_B8A_20m.jp2'], 'B11': ['**/R20m/*_B11_20m.jp2'],\n",
    "        },\n",
    "    },\n",
    "}\n",
    "NODATA_VALUE = -9999.0\n",
    "OUTPUT_DTYPE = np.float32\n",
    "\n",
    "\n",
    "# ── Helper Functions ──────────────────────────────────────────────────────────\n",
    "def load_scaler_and_encoder(scaler_path, label_encoder_path, positive_class_label):\n",
    "    scaler, le, pos_idx = None, None, -1\n",
    "    try:\n",
    "        scaler = joblib.load(scaler_path)\n",
    "        print(f'Scaler loaded: {scaler_path}')\n",
    "    except Exception as e:\n",
    "        print(f'Error loading scaler: {e}'); return None, None, -1\n",
    "    try:\n",
    "        le = joblib.load(label_encoder_path)\n",
    "        print(f'LabelEncoder loaded: {label_encoder_path}')\n",
    "        pos_idx = le.transform([str(positive_class_label)])[0]\n",
    "        print(f'Positive class \"{positive_class_label}\" -> index {pos_idx}')\n",
    "    except Exception as e:\n",
    "        print(f'Error loading LabelEncoder: {e}'); return scaler, None, -1\n",
    "    return scaler, le, pos_idx\n",
    "\n",
    "\n",
    "def find_scene_band_files(scene_path, scene_id, sensor_config):\n",
    "    band_files = {}\n",
    "    for band_id, pattern_list in sensor_config['file_patterns'].items():\n",
    "        for pattern in pattern_list:\n",
    "            found = sorted(glob.glob(os.path.join(scene_path, pattern), recursive='**' in pattern))\n",
    "            if found:\n",
    "                band_files[band_id] = found[0]; break\n",
    "    found_concepts = {sensor_config['band_map_to_train'][b] for b in band_files if b in sensor_config['band_map_to_train']}\n",
    "    required = {'Blue', 'Green', 'Red', 'SWIR1'}\n",
    "    if not required.issubset(found_concepts) or 'NIR' not in found_concepts:\n",
    "        missing = (required - found_concepts) | ({'NIR'} if 'NIR' not in found_concepts else set())\n",
    "        print(f'Error: Missing bands for {scene_id}: {missing}'); return None\n",
    "    return band_files\n",
    "\n",
    "\n",
    "def classify_scene(scene_id, band_files_dict, sensor_cfg, model_info,\n",
    "                   scaler, positive_class_index, output_dir):\n",
    "    \"\"\"Classify a single scene with a single model. Loads all bands into RAM first.\"\"\"\n",
    "    sensor_name = sensor_cfg['name']\n",
    "    target_res  = sensor_cfg['target_resolution']\n",
    "    model_obj   = model_info['model_obj']\n",
    "    model_type  = model_info['type']\n",
    "    name_prefix = model_info['name_prefix']\n",
    "\n",
    "    out_file = f'fractional_cover_{sensor_name}_{scene_id}_{target_res}m_{name_prefix}.tif'\n",
    "    out_path = os.path.join(output_dir, out_file)\n",
    "\n",
    "    if os.path.exists(out_path):\n",
    "        print(f'    Output exists, skipping: {out_path}'); return out_path\n",
    "\n",
    "    # Build band map (use only first NIR band found)\n",
    "    scene_band_map, has_nir = {}, False\n",
    "    for s_band, concept in sensor_cfg['band_map_to_train'].items():\n",
    "        if s_band not in band_files_dict: continue\n",
    "        if concept == 'NIR':\n",
    "            if not has_nir: scene_band_map[s_band] = concept; has_nir = True\n",
    "        else:\n",
    "            scene_band_map[s_band] = concept\n",
    "\n",
    "    # Reference band for grid and windows\n",
    "    ref_bid = next(b for b, r in sensor_cfg['bands_needed'].items()\n",
    "                   if r == target_res and b in band_files_dict)\n",
    "\n",
    "    # Read profile\n",
    "    with rasterio.open(band_files_dict[ref_bid]) as src:\n",
    "        profile = src.profile.copy()\n",
    "        profile.pop('blockxsize', None); profile.pop('blockysize', None); profile.pop('tiled', None)\n",
    "        profile.update(dtype=OUTPUT_DTYPE, count=1, nodata=NODATA_VALUE, compress='lzw', driver='GTiff')\n",
    "        w, h = src.width, src.height\n",
    "    print(f'\\n  Scene: {scene_id} | Model: {name_prefix} | Grid: {w}x{h}px')\n",
    "\n",
    "    # Pre-load all bands into RAM\n",
    "    full_bands, full_nodata = {}, {}\n",
    "    for s_bid in scene_band_map:\n",
    "        with rasterio.open(band_files_dict[s_bid]) as src:\n",
    "            full_bands[s_bid]  = src.read(1)\n",
    "            full_nodata[s_bid] = int(src.nodata or 0)\n",
    "    print('    All bands loaded into RAM.')\n",
    "\n",
    "    t_pred, n_pix = 0.0, 0\n",
    "\n",
    "    with rasterio.open(out_path, 'w', **profile) as dst:\n",
    "        with rasterio.open(band_files_dict[ref_bid]) as src:\n",
    "            windows = list(src.block_windows(1))\n",
    "\n",
    "        for _, window in tqdm(windows, desc=f'  Classifying ({name_prefix})', unit='block', leave=False):\n",
    "            wh, ww = window.height, window.width\n",
    "            if wh == 0 or ww == 0: continue\n",
    "            out_blk = np.full((wh, ww), NODATA_VALUE, dtype=OUTPUT_DTYPE)\n",
    "\n",
    "            bands_raw, valid_mask, ok = {}, None, True\n",
    "            for s_bid in scene_band_map:\n",
    "                try:\n",
    "                    band_res = sensor_cfg['bands_needed'][s_bid]\n",
    "                    ratio = band_res / target_res\n",
    "                    if ratio == 1.0:\n",
    "                        slc = (slice(window.row_off, window.row_off + wh),\n",
    "                               slice(window.col_off, window.col_off + ww))\n",
    "                    else:\n",
    "                        sr0 = int(window.row_off // ratio)\n",
    "                        sc0 = int(window.col_off // ratio)\n",
    "                        sr1 = int(math.ceil((window.row_off + wh) / ratio))\n",
    "                        sc1 = int(math.ceil((window.col_off + ww) / ratio))\n",
    "                        slc = (slice(sr0, sr1), slice(sc0, sc1))\n",
    "                    native = full_bands[s_bid][slc]\n",
    "                    if ratio != 1.0:\n",
    "                        if not CV2_AVAILABLE or native.size == 0: ok = False; break\n",
    "                        native = cv2.resize(native.astype(np.float32), (ww, wh), interpolation=cv2.INTER_LANCZOS4)\n",
    "                    bands_raw[s_bid] = native\n",
    "                    mask = (native.astype(np.int64) != full_nodata[s_bid])\n",
    "                    valid_mask = mask if valid_mask is None else (valid_mask & mask)\n",
    "                except Exception:\n",
    "                    ok = False; break\n",
    "\n",
    "            if not ok or valid_mask is None or not valid_mask.any():\n",
    "                dst.write(out_blk, 1, window=window); continue\n",
    "\n",
    "            s_scale, s_off = sensor_cfg['scale'], sensor_cfg['offset']\n",
    "            n_valid = int(valid_mask.sum())\n",
    "            feats = np.zeros((n_valid, len(TRAINING_BAND_ORDER)), dtype=np.float64)\n",
    "\n",
    "            spectra = {}\n",
    "            for s_bid, raw in bands_raw.items():\n",
    "                spectra[s_bid] = (raw[valid_mask].astype(np.float64) * s_scale) + s_off\n",
    "\n",
    "            if sensor_name == 'Landsat-8' and not DISABLE_L8_HARMONIZATION:\n",
    "                hc = sensor_cfg.get('harmonization_coeffs', {})\n",
    "                for s_bid, concept in scene_band_map.items():\n",
    "                    if concept in hc and s_bid in spectra:\n",
    "                        spectra[s_bid] = hc[concept]['slope'] * spectra[s_bid] + hc[concept]['intercept']\n",
    "\n",
    "            for i, concept in enumerate(TRAINING_BAND_ORDER):\n",
    "                src_bid = next((b for b, c in scene_band_map.items() if c == concept), None)\n",
    "                if src_bid and src_bid in spectra:\n",
    "                    feats[:, i] = spectra[src_bid]\n",
    "\n",
    "            nan_mask = ~np.isnan(feats).any(axis=1)\n",
    "            if not nan_mask.any():\n",
    "                dst.write(out_blk, 1, window=window); continue\n",
    "\n",
    "            feats_scaled = scaler.transform(feats[nan_mask].astype(np.float32))\n",
    "            preds = np.full(nan_mask.sum(), np.nan, dtype=OUTPUT_DTYPE)\n",
    "\n",
    "            try:\n",
    "                t0 = time.perf_counter()\n",
    "                if model_type == 'tflite':\n",
    "                    interp = model_obj\n",
    "                    inp_d  = interp.get_input_details()[0]\n",
    "                    out_d  = interp.get_output_details()[0]\n",
    "                    is_cnn = inp_d['shape'].ndim == 3 or len(inp_d['shape']) > 2\n",
    "                    inp_data = feats_scaled.reshape(feats_scaled.shape[0], feats_scaled.shape[1], 1) \\\n",
    "                               if (len(inp_d['shape']) == 3 and inp_d['shape'][-1] == 1) else feats_scaled\n",
    "                    bs = inp_data.shape[0]\n",
    "                    if inp_d['shape'][0] != bs:\n",
    "                        interp.resize_tensor_input(inp_d['index'], [bs] + list(inp_d['shape'][1:]))\n",
    "                        interp.allocate_tensors()\n",
    "                    interp.set_tensor(inp_d['index'], inp_data.astype(inp_d['dtype']))\n",
    "                    interp.invoke()\n",
    "                    preds = interp.get_tensor(out_d['index']).flatten()\n",
    "                elif model_type == 'xgboost':\n",
    "                    preds = model_obj.predict_proba(feats_scaled.astype(np.float32))[:, positive_class_index]\n",
    "                else:\n",
    "                    raise ValueError(f'Unknown model type: {model_type}')\n",
    "                t_pred += time.perf_counter() - t0\n",
    "                n_pix  += feats_scaled.shape[0]\n",
    "            except Exception as e:\n",
    "                print(f'\\n    Prediction error: {e}'); traceback.print_exc()\n",
    "                dst.write(out_blk, 1, window=window); continue\n",
    "\n",
    "            # Map predictions back to full output block\n",
    "            tmp = np.full(n_valid, NODATA_VALUE, dtype=OUTPUT_DTYPE)\n",
    "            tmp[nan_mask] = preds\n",
    "            out_blk[valid_mask] = tmp\n",
    "            out_blk[np.isnan(out_blk) | np.isinf(out_blk)] = NODATA_VALUE\n",
    "            dst.write(out_blk, 1, window=window)\n",
    "\n",
    "    if n_pix > 0 and t_pred > 0:\n",
    "        print(f'    Inference: {n_pix:,} px | {n_pix/t_pred:,.0f} px/s | {t_pred/n_pix*1e6:.2f} µs/px')\n",
    "    print(f'  Saved: {out_path}')\n",
    "    return out_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Models & Artefacts\n",
    "\n",
    "Load the feature scaler, label encoder, and all selected models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALER_PATH       = os.path.join(MODEL_ROOT_DIR, 'scaler_classification.joblib')\n",
    "LABEL_ENC_PATH    = os.path.join(MODEL_ROOT_DIR, 'label_encoder_classification.joblib')\n",
    "\n",
    "scaler, le, positive_class_index = load_scaler_and_encoder(\n",
    "    SCALER_PATH, LABEL_ENC_PATH, POSITIVE_CLASS_LABEL\n",
    ")\n",
    "\n",
    "all_loaded_models = []\n",
    "\n",
    "# Load TFLite models\n",
    "if TF_AVAILABLE:\n",
    "    for fname in TFLITE_MODELS:\n",
    "        path = os.path.join(MODEL_ROOT_DIR, fname)\n",
    "        if not os.path.exists(path):\n",
    "            print(f'Skipping (not found): {path}'); continue\n",
    "        try:\n",
    "            interp = tf.lite.Interpreter(model_path=path)\n",
    "            interp.allocate_tensors()\n",
    "            all_loaded_models.append({\n",
    "                'name_prefix': os.path.splitext(fname)[0],\n",
    "                'model_obj': interp,\n",
    "                'type': 'tflite',\n",
    "            })\n",
    "            print(f'Loaded TFLite : {fname}')\n",
    "        except Exception as e:\n",
    "            print(f'Error loading {fname}: {e}')\n",
    "else:\n",
    "    print('Skipping TFLite models (TensorFlow not available).')\n",
    "\n",
    "# Load XGBoost models\n",
    "if XGB_AVAILABLE:\n",
    "    for fname in XGBOOST_MODELS:\n",
    "        path = os.path.join(MODEL_ROOT_DIR, fname)\n",
    "        if not os.path.exists(path):\n",
    "            print(f'Skipping (not found): {path}'); continue\n",
    "        try:\n",
    "            model = joblib.load(path)\n",
    "            if isinstance(model, xgb.XGBClassifier):\n",
    "                model.set_params(device='cuda')  # ensure GPU inference\n",
    "                all_loaded_models.append({\n",
    "                    'name_prefix': os.path.splitext(fname)[0],\n",
    "                    'model_obj': model,\n",
    "                    'type': 'xgboost',\n",
    "                })\n",
    "                print(f'Loaded XGBoost: {fname}')\n",
    "        except Exception as e:\n",
    "            print(f'Error loading {fname}: {e}')\n",
    "else:\n",
    "    print('Skipping XGBoost models (XGBoost not available).')\n",
    "\n",
    "print(f'\\nTotal models loaded: {len(all_loaded_models)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Classify Satellite Scenes\n",
    "\n",
    "Run every loaded model on both the example Landsat-8 and Sentinel-2 scenes.\n",
    "Each combination produces one GeoTIFF fractional cover map in `output/fractional_cover_maps/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANDSAT_SCENE_ID  = 'LC08_L1GT_016046_20150723_20200908_02_T2'\n",
    "SENTINEL_SCENE_ID = 'S2B_MSIL2A_20180827T160059_N0500_R097_T16QGH_20230624T195041.SAFE'\n",
    "\n",
    "SCENES = [\n",
    "    ('Landsat-8',  os.path.join(DATA_ROOT_DIR, 'landsat',  LANDSAT_SCENE_ID),  LANDSAT_SCENE_ID),\n",
    "    ('Sentinel-2', os.path.join(DATA_ROOT_DIR, 'sentinel', SENTINEL_SCENE_ID), SENTINEL_SCENE_ID),\n",
    "]\n",
    "\n",
    "all_output_paths = []\n",
    "\n",
    "for model_info in all_loaded_models:\n",
    "    print(f'\\n===== Model: {model_info[\"name_prefix\"]} ({model_info[\"type\"]}) =====')\n",
    "    for sensor_key, scene_path, scene_id in SCENES:\n",
    "        sensor_cfg = SENSOR_CONFIG[sensor_key]\n",
    "        band_files = find_scene_band_files(scene_path, scene_id, sensor_cfg)\n",
    "        if not band_files:\n",
    "            print(f'  Skipping {scene_id} (band files not found).'); continue\n",
    "        out = classify_scene(\n",
    "            scene_id, band_files, sensor_cfg, model_info,\n",
    "            scaler, positive_class_index, OUTPUT_DIR,\n",
    "        )\n",
    "        if out:\n",
    "            all_output_paths.append(out)\n",
    "\n",
    "print(f'\\nAll done. {len(all_output_paths)} maps generated:')\n",
    "for p in sorted(all_output_paths):\n",
    "    print(f'  {p}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Fractional Cover Maps\n",
    "\n",
    "Display all generated maps. Pixel values represent the predicted **probability of Sargassum presence** (0 = no sargassum, 1 = sargassum). Nodata pixels are shown in white."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_cover_map(tif_path, title, ax, cmap='YlOrBr'):\n",
    "    \"\"\"Display a fractional cover GeoTIFF on a matplotlib axis.\"\"\"\n",
    "    with rasterio.open(tif_path) as src:\n",
    "        data   = src.read(1).astype(np.float32)\n",
    "        nodata = src.nodata\n",
    "    if nodata is not None:\n",
    "        data = np.where(data == nodata, np.nan, data)\n",
    "    im = ax.imshow(data, cmap=cmap, vmin=0, vmax=1, interpolation='nearest')\n",
    "    ax.set_title(title, fontsize=8)\n",
    "    ax.axis('off')\n",
    "    return im\n",
    "\n",
    "\n",
    "tif_files = sorted(glob.glob(os.path.join(OUTPUT_DIR, 'fractional_cover_*.tif')))\n",
    "print(f'Found {len(tif_files)} fractional cover maps.')\n",
    "\n",
    "if tif_files:\n",
    "    n_cols = 2\n",
    "    n_rows = math.ceil(len(tif_files) / n_cols)\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 7, n_rows * 5))\n",
    "    axes_flat = np.array(axes).flatten()\n",
    "\n",
    "    for i, tif_path in enumerate(tif_files):\n",
    "        label = os.path.basename(tif_path).replace('fractional_cover_', '').replace('.tif', '')\n",
    "        try:\n",
    "            im = show_cover_map(tif_path, label, axes_flat[i])\n",
    "            plt.colorbar(im, ax=axes_flat[i], label='Sargassum probability', shrink=0.85, pad=0.02)\n",
    "        except Exception as e:\n",
    "            axes_flat[i].text(0.5, 0.5, f'Error:\\n{e}', ha='center', va='center',\n",
    "                              transform=axes_flat[i].transAxes, fontsize=8)\n",
    "            axes_flat[i].axis('off')\n",
    "\n",
    "    for j in range(len(tif_files), len(axes_flat)):\n",
    "        axes_flat[j].axis('off')\n",
    "\n",
    "    plt.suptitle('Sargassum Fractional Cover Maps', fontsize=14, fontweight='bold', y=1.01)\n",
    "    plt.tight_layout()\n",
    "    viz_path = os.path.join(OUTPUT_DIR, 'comparison_visualization.png')\n",
    "    plt.savefig(viz_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f'Visualization saved to: {viz_path}')\n",
    "else:\n",
    "    print('No output maps found. Run Section 5 first.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated the full inference workflow:\n",
    "- **TFLite** models (INT8 / FLOAT16) via the TensorFlow Lite interpreter\n",
    "- **XGBoost GPU** model via `predict_proba`\n",
    "\n",
    "To extend the workflow:\n",
    "- Add your own satellite scenes to `satellite_data/` and add entries to the `SCENES` list.\n",
    "- Add or remove model filenames from `TFLITE_MODELS` / `XGBOOST_MODELS`.\n",
    "- The output GeoTIFFs can be opened in QGIS, ArcGIS, or any GIS tool for further analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}